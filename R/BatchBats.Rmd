```{r setup, include=FALSE}
#knitr::opts_chunk$set(cache=TRUE)
```


Bat Bioacoustics
========================================================

Code based on documentation on https://revspace.nl/StereoBatRecorder

This code processes all of the recordings

Load the required libraries
---------------------------
```{r} 
#never ever ever convert strings to factors
options(stringsAsFactors = FALSE)

library(tuneR) #readMP3
source("/home/cbdavis/Desktop/tuneR/R/readWave.R") # patched version of readWave
library(seewave)
library(signal) # Matlab-style filters
library(ggplot2) # plotting
library(sqldf) # run SQL queries over data frames
```

```{r}

lowPassFilter <- function(originalWave){
  tmp = butter(4, 0.2, "high")
  a = tmp$a
  b = tmp$b
  
  filteredWave = Wave(left = as.numeric(filter(b, a, originalWave@left)), 
                      right = as.numeric(filter(b, a, originalWave@right)), 
                      samp.rate = originalWave@samp.rate, 
                      bit = originalWave@bit, 
                      pcm = originalWave@pcm)
  return(filteredWave)
  }

windowLength = 256

baseDir = "/home/cbdavis/projects/BioAcoustics/Bats/stereobat"
files = list.files(path=baseDir, pattern="*.wav", recursive=TRUE, full.names=TRUE)

lagData = data.frame()
entropy_df = data.frame()
for (file in files){
  #originalWave = readMP3(file)
  originalWave = readWave(file)
  filteredWave = lowPassFilter(originalWave)
  rm(originalWave)
  
  cutoffValue = 0.9
  csh = csh(filteredWave, wl=windowLength, ovlp=0, plot=FALSE)
  csh_time = csh[,1]
  csh_values = csh[,2]
  
  entropy_df = rbind(entropy_df, 
                     data.frame(fullPath = file, 
                                csh_time = csh_time, 
                                csh_values = csh_values, 
                                csh_cutoff = max(csh_values) * cutoffValue))
  
  # Now segment the audio based on the entropy values.  Use a time buffer before and after.
  sampleCount = 1
  audioBuffer = 0.025
  audioSegments = list()
  locs = which(csh_values < max(csh_values) * cutoffValue)
  startLoc = locs[1]
  for (i in c(2:(length(locs)-1))){
    if ((locs[i+1] - locs[i]) > 1){
      endLoc = locs[i]
      if ((endLoc - startLoc) > 5){ # TODO figure out a smarter way of figuring out if the signal is long enough
        # cutw only returns a mono signal if a stereo signal is used as input, 
        # so we perform cuts on both channels independently
        
        audioStart = csh_time[startLoc]-audioBuffer
        
        # make sure don't have negative starting value
        if (audioStart < 0){
          audioStart = 0
          }
        
        audioEnd = csh_time[endLoc] + audioBuffer
        
        
        audioSegmentLeft = as.numeric(cutw(filteredWave@left, 
                                           f=filteredWave@samp.rate,  
                                           from=audioStart, 
                                           to=audioEnd, 
                                           plot=FALSE, output="matrix"))
        audioSegmentRight = as.numeric(cutw(filteredWave@right, 
                                            f=filteredWave@samp.rate,  
                                            from=audioStart, 
                                            to=audioEnd, 
                                            plot=FALSE, output="matrix"))
        audioSegment = Wave(audioSegmentLeft, audioSegmentRight, samp.rate = filteredWave@samp.rate, bit=filteredWave@bit)
        audioSegments = c(audioSegments, audioSegment)
        
        # TODO lag.max is completely made up, should be set to something sensible based on max tdiff between microphones
        xcov_info = ccf(audioSegment@left, audioSegment@right, lag.max=250, type="covariance", plot=FALSE)
        lag = xcov_info$lag
        r = xcov_info$acf
        # take absolute value of the hilbert transform to get the envelope of the correlation
        r2 = abs(hilbert(r, filteredWave@samp.rate))
        # normalize r2
        r2 = (r2 - min(r2))/(max(r2) - min(r2))
        lagData = rbind(lagData, cbind(file, 
                                       gsub(paste(baseDir, "/", sep=""), "", file), 
                                       sampleCount, 
                                       audioStart, 
                                       audioEnd, 
                                       lag*((1/audioSegment@samp.rate)*1000),
                                       r2))
        sampleCount = sampleCount + 1
        }
      startLoc = locs[i+1]
      }
    }
  }

entropy_df$relativePath = gsub(paste(baseDir, "/", sep=""), "", entropy_df$fullPath)
```

Continuous Spectral Entropy with Cutoff Value Used for Segmentation
-------------------------------------------------------------------
Parts of the audio signal with entropy values lower than the cutoff (in red) are kept for further analysis
```{r fig.width=20, fig.height=20}
ggplot(entropy_df, aes(x=csh_time, y=csh_values)) + geom_line() + 
  geom_line(aes(x=csh_time, y=csh_cutoff, colour="red")) + 
  facet_wrap(~relativePath)
```

Time Lag Between Microphone Channels
------------------------------------
Points indicate max correlation
```{r fig.width=20, fig.height=20}
lagData = as.data.frame(lagData)
colnames(lagData) = c("fullPath", "relativePath", "sample", "audioStart", "audioEnd", "lag", "r")

lagData$audioStart = as.numeric(lagData$audioStart)
lagData$audioEnd = as.numeric(lagData$audioEnd)
lagData$r = as.numeric(lagData$r)
lagData$lag = as.numeric(lagData$lag)

maxCorrelations = sqldf("select *, max(r) from lagData group by sample, fullPath")

maxCorrelations$audioStart = as.numeric(maxCorrelations$audioStart)
maxCorrelations$audioEnd = as.numeric(maxCorrelations$audioEnd)
maxCorrelations$r = as.numeric(maxCorrelations$r)
maxCorrelations$lag = as.numeric(maxCorrelations$lag)

# set correlations for min & max lag (the boundaries of the window) to zero
# this helps to draw the polygons correctly
lagData$r[which(lagData$lag == max(lagData$lag))] = 0
lagData$r[which(lagData$lag == min(lagData$lag))] = 0

lagData = sqldf("select * from lagData order by fullPath, sample, lag")

ggplot(lagData) + geom_line(aes(x=audioEnd+r, y=lag, group=sample), alpha=0.25) + 
  geom_point(data=maxCorrelations, aes(x=audioEnd+r, y=lag)) + facet_wrap(~relativePath)
```
